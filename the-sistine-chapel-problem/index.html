<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>The Sistine Chapel Problem - Jermain C. Kaminski</title><meta name="description" content="In a time when Large Language Models (LLM) can write beautiful essays and solve hard problems in seconds, educators have to ask themselves a basic question: what is the most important thing about learning? The answer, which may surprise you, can be found in a park bench conversation from a 1997 movie (video)."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="stylesheet" href="https://jermainkaminski.com/media/plugins/staticSearch/static.search.min.css"><link rel="canonical" href="https://jermainkaminski.com/the-sistine-chapel-problem/"><meta property="og:title" content="The Sistine Chapel Problem"><meta property="og:image" content="https://jermainkaminski.com/media/posts/19/Will20Hunting.jpg.webp"><meta property="og:image:width" content="1280"><meta property="og:image:height" content="720"><meta property="og:site_name" content="Jermain C. Kaminski"><meta property="og:description" content="In a time when Large Language Models (LLM) can write beautiful essays and solve hard problems in seconds, educators have to ask themselves a basic question: what is the most important thing about learning? The answer, which may surprise you, can be found in a park bench conversation from a 1997 movie (video)."><meta property="og:url" content="https://jermainkaminski.com/the-sistine-chapel-problem/"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@jermainkaminski"><meta name="twitter:title" content="The Sistine Chapel Problem"><meta name="twitter:description" content="In a time when Large Language Models (LLM) can write beautiful essays and solve hard problems in seconds, educators have to ask themselves a basic question: what is the most important thing about learning? The answer, which may surprise you, can be found in a park bench conversation from a 1997 movie (video)."><meta name="twitter:image" content="https://jermainkaminski.com/media/posts/19/Will20Hunting.jpg.webp"><link rel="alternate" type="application/atom+xml" href="https://jermainkaminski.com/feed.xml" title="Jermain C. Kaminski - RSS"><link rel="alternate" type="application/json" href="https://jermainkaminski.com/feed.json" title="Jermain C. Kaminski - JSON"><link rel="preload" href="https://jermainkaminski.com/assets/dynamic/fonts/merriweather/merriweather.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="https://jermainkaminski.com/assets/css/style.css?v=8c42de260bcd6ce6a966ca84bc880683"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://jermainkaminski.com/the-sistine-chapel-problem/"},"headline":"The Sistine Chapel Problem","datePublished":"2025-09-08T21:50+02:00","dateModified":"2025-09-10T16:33+02:00","image":{"@type":"ImageObject","url":"https://jermainkaminski.com/media/posts/19/Will20Hunting.jpg.webp","height":720,"width":1280},"description":"In a time when Large Language Models (LLM) can write beautiful essays and solve hard problems in seconds, educators have to ask themselves a basic question: what is the most important thing about learning? The answer, which may surprise you, can be found in a park bench conversation from a 1997 movie (video).","author":{"@type":"Person","name":"Jermain Kaminski","url":"https://jermainkaminski.com/authors/jermain-kaminski/"},"publisher":{"@type":"Organization","name":"Jermain Kaminski"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet"><script defer="defer" data-domain="jermainkaminski.com" src="https://plausible.io/js/script.file-downloads.outbound-links.js"></script><script>window.plausible = window.plausible || function() { (window.plausible.q = window.plausible.q || []).push(arguments) }</script></head><body class="post-template"><header class="header" id="js-header"><div class="wrapper"><a class="logo" href="https://jermainkaminski.com/">Jermain C. Kaminski</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://jermainkaminski.com/welcome/" target="_self">About</a></li><li><a href="https://jermainkaminski.com/research/" target="_self">Research</a></li><li><a href="https://jermainkaminski.com/publications/" target="_self">Publications</a></li><li><a href="https://jermainkaminski.com/speaking-and-workshops/" target="_self">Speaking</a></li><li><a href="https://jermainkaminski.com/students/" target="_self">Students</a></li><li><a href="https://jermainkaminski.com/teaching/" target="_self">Teaching</a></li><li><a href="mailto:j.kaminski@maastrichtuniversity.nl" target="_self">Contact</a></li><li><a href="https://bsky.app/profile/jermainkaminski.bsky.social">Bluesky</a></li></ul></nav><div class="search"><div class="search__overlay js-search-overlay"><div class="wrapper search__overlay-inner"><form action="#search" class="search__form"><input class="search__input" type="search" placeholder="Search" aria-label="Search"></form><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Submit"><svg role="presentation" focusable="false"><use xlink:href="https://jermainkaminski.com/assets/svg/svg-map.svg#search"/></svg></button></div></div></header><main class="main post"><div class="wrapper"><div class="content"><article><header class="content__header content__header--partial"><div class="content__header--partial__left"><div><time datetime="2025-09-08T21:50" class="content__meta-date">September 8, 2025</time><h1 class="content__title">The Sistine Chapel Problem</h1><div class="author content__meta-author--partial"><img src="https://jermainkaminski.com/media/website/Jermain.jpg" loading="eager" height="1939" width="1939" class="author__avatar" alt="Jermain Kaminski"><div class="author__info"><a href="https://jermainkaminski.com/authors/jermain-kaminski/" class="invert author__name" rel="author">Jermain Kaminski</a><p>Jermain Kaminski is a researcher and professor specializing in entrepreneurship, strategy, and machine learning, with a focus on how data-driven methods can improve decision-making in innovation and early-stage ventures.</p></div></div></div></div><figure class="content__hero-image content__hero-image--partial"><img src="https://jermainkaminski.com/media/posts/19/Will20Hunting.jpg.webp" srcset="https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-xs.webp 300w, https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-sm.webp 480w, https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-md.webp 768w, https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-xl.webp 1200w, https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-xxl.webp 1600w, https://jermainkaminski.com/media/posts/19/responsive/Will20Hunting.jpg-xxxl.webp 2560w" sizes="(max-width: 2560px) 100vw, 2560px" loading="eager" height="720" width="1280" alt=""></figure></header><div class="content__inner content__entry"><p class="dropcap">In a time when Large Language Models (LLM) can write beautiful essays and solve hard problems in seconds, educators have to ask themselves a basic question: what is the most important thing about learning? The answer, which may surprise you, can be found in a <a href="https://www.youtube.com/watch?v=8GY3sO47YYo" target="_blank" rel="noopener noreferrer">park bench conversation from a 1997 movie</a> (video).</p><p class="whitespace-normal break-words">When we use an LLM to complete a task, whether it's coding, solving a modeling problem, or exploring a complex idea, we receive what appears to be a perfect product: well-structured, grammatically correct, and convincing. But this perfection masks an absence. We haven't wrestled with confused thoughts, haven't experienced the frustration of contradictions and debugging that won't resolve, haven't felt the satisfaction of finally understanding something that once seemed impenetrable.</p><p class="whitespace-normal break-words">Growth has always been imperfect by design. The crossed-out sentences, the failed attempts running code, the flash of insight amid confusion. These are not bugs in the process of thinking but features. They represent understanding being forged rather than downloaded, knowledge earned rather than accessed. This tension between information and experience, between knowing about something and knowing it, predates artificial intelligence. But what if the greatest threat isn't that we work with AI, but that we'll risk the capacity for original thought? How will we cultivate innovation and deep expertise if we, and especially so students, never experience the disorientation of not knowing? When every difficult question yields an instant, polished answer, who will develop the intellectual muscle to tackle problems that have no solutions yet? The struggle itself, the messy, frustrating, ultimately transformative process of grappling with complexity, may be where human capability actually lives. Not in the answers we produce, but in the cognitive strength we build by searching for them.</p><p class="whitespace-normal break-words"><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">In my view, a more than twenty-year-old film about an intellectually talented janitor from South Boston offers an unexpected lens for understanding what we're about to lose.</span></p><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">What It Smells Like in the Sistine Chapel</h2><p class="whitespace-normal break-words">In <em>Good Will Hunting</em>, psychologist Sean Maguire (Robin Williams) confronts Will Hunting (Matt Damon), a brilliant but emotionally guarded young janitor who can recite facts about virtually anything, with a profound challenge about the nature of knowledge:</p><blockquote><p class="whitespace-normal break-words">"If I asked you about art, you'd probably give me the skinny on every art book ever written. Michelangelo, you know a lot about him. Life's work, political aspirations, him and the pope, sexual orientations, the whole works, right? But I'll bet you can't tell me what it smells like in the Sistine Chapel. You've never actually stood there and looked up at that beautiful ceiling."</p></blockquote><p class="whitespace-normal break-words">This scene makes clear a difference that has become very important in our time. Large Language Models, like Will in a the famous Harvard bar scene at the inception of the plot, can provide the surface on any topic: <a href="https://www.youtube.com/watch?v=LMD2vUErcYU" target="_blank" rel="noopener noreferrer">dates, facts, connections, analysis</a>. They can tell you about Michelangelo's techniques, the chapel's dimensions, the theological symbolism of each panel. But they cannot tell you what it smells like in that sacred space, the trace of incense from morning mass, how your neck aches from craning upward, or the short hush that falls over tourists as they enter the chapel. They do did not experience the occasional gasp when someone spots Adam's finger. They cannot convey how small you feel standing beneath the human-made frescoes.</p><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5"><figure class="post__image"><img loading="lazy" src="https://jermainkaminski.com/media/posts/19/pierre-goiffon-aR_COwiGzP0-unsplash.jpg" alt="" width="1920" height="1280" sizes="(max-width: 1200px) 100vw, 1200px" srcset="https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-xs.webp 300w, https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-sm.webp 480w, https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-md.webp 768w, https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-xl.webp 1200w, https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-xxl.webp 1600w, https://jermainkaminski.com/media/posts/19/responsive/pierre-goiffon-aR_COwiGzP0-unsplash-xxxl.webp 2560w"></figure></h2><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">The "How" Versus the "Why"</h2><p><a href="https://www.sciencedirect.com/science/article/pii/S0896627317305093" target="_blank" rel="noopener noreferrer">Despite large advances in neuroscience-inspired machine learning</a>, and evolutionary algorithms that taught computers to fail via <a href="https://www.sciencedirect.com/science/article/pii/S0893608022001150" target="_blank" rel="noopener noreferrer">reinforcement learning</a>, failure taught them optimization, not the weight of disappointment, not the frustration of learning. Philosophers call this the <em>explanatory gap </em>(Levine, 1983)<em>, or Dasein </em>(Heidegger, 1927);<em> </em>they process signals but never cross into sensation.</p><p class="whitespace-normal break-words">Without doubt, computers excel at the mechanics of knowledge: the <em>how</em>. They can demonstrate problem-solving steps, generate structurally sound arguments, and synthesize information from many databases it crawled or is able to access ad-hoc. This is undeniably valuable for education. Students can receive instant feedback, explore ideas at their own pace, and access personalized tutoring, complementing what we for instance do at Maastricht University in problem based learning (PBL).</p><p class="whitespace-normal break-words">Yet education, at its core, has always been about the <em>why</em>. Why does this mathematical proof matter? Why should we care about the fall of Rome? Why does this poem move us? Why do I control for collinearity with the Variance Inflation Factor (<a href="https://journals.sagepub.com/doi/abs/10.1177/10944281231216381" target="_blank" rel="noopener noreferrer">or why should I not?</a>). These questions require not just information processing but understanding. The kind of insight that emerges from struggle, contemplation, and failure.</p><p>One of my undergraduate professors for economics and philosophy, <a href="https://priddat.de/biographie/" target="_blank" rel="noopener noreferrer">Birger Priddat</a>, once ended a lecture with a claim that followed me: "By the end of your studies, you should have read a stable of books at least taller than yourself. You need to <em>experience</em> it, you need to <em>doubt</em> it, at the risk of being wrong". When Sean challenges Will about the Sistine Chapel, Sean is making Priddat's point: there is knowledge you can access and knowledge you must undergo. The stack of books taller than yourself is not about the information contained within their pages, which any LLM could summarize in seconds. It's about becoming someone different by the time you reach the top: tired, changed, and carrying not just what you've read but who you've become through reading it.</p><p>We're all experiencing this shift in how research develops. Post-GPT, theses cite more sources than ever but engage less deeply. What one might calls stratospheric scholarship, flying at 30,000 feet above the actual methodological terrain and touching topics one at a time. With LLMs, literature reviews have become remarkably comprehensive. More sources, broader coverage, impressive bibliographies. Who could resist such an efficient research assistant? Yet something subtle is lost in this efficiency: the deep, sometimes frustrating engagement with a paper's methodology, sampling, the wrestling with its limitations, the slow dawning of what it really means in context. In thesis defenses, this trade-off becomes visible: students have genuinely worked hard, used the tools available to them, yet find themselves strangers to their own citations. It's not a failure of effort but a consequence of tools that make the wrong parts easy.</p><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">Your Move, Chief</h2><p>In the movie, Sean continues his challenge to Will:</p><blockquote><p>You're an orphan right? You think I know the first thing about how hard your life has been, how you feel, who you are, because I read Oliver Twist?</p></blockquote><p>Here's another realisation: genuine knowledge is individualised and influenced by our individual experiences with other people. The bench scene serves as a reminder that transformative education is also relational, which is perhaps its most significant lesson. Sean's breakthrough with Will isn't the result of superior knowledge or clever reasoning. It comes from being vulnerable, from sharing his own grief over his wife's passing, and from having a real human connection. "Your move," he says, asking Will to engage authentically rather than simply reciting facts.</p><figure class="post__image"><img loading="lazy" src="https://jermainkaminski.com/media/posts/19/1HfekqjcJN1HXe2zWWGaG8g2x.jpg" alt="" width="1242" height="666" sizes="(max-width: 1200px) 100vw, 1200px" srcset="https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-xs.webp 300w, https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-sm.webp 480w, https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-md.webp 768w, https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-xl.webp 1200w, https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-xxl.webp 1600w, https://jermainkaminski.com/media/posts/19/responsive/1HfekqjcJN1HXe2zWWGaG8g2x-xxxl.webp 2560w"></figure><p class="whitespace-normal break-words">This relational dimension, the classroom discussions where ideas spark and clash, the mentorship that shapes not just what we know but who we become, cannot be algorithmatically reproduced. Also from the educator's perspective, an LLM can provide feedback, but it cannot see the particular student before it, the thought vector one comes from, cannot recognize the moment when confusion shifts to comprehension, cannot share in the joy of discovery.</p><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">Desirable Difficulties</h2><p class="whitespace-normal break-words">The idea is not to banish LLMs from education. They are powerful tools that, used thoughtfully, can enhance learning. Students can use them to explore ideas, check understanding, and overcome barriers to entry in complex subjects. In my own entrepreneurship teaching, I encourage students to use text, image, and video generation methods to imagine future products and services. In causal inference, I employ LLM to look for <a href="https://github.com/py-why/pywhyllm" target="_blank" rel="noopener noreferrer">potential confounders or omitted variables</a>. That being said, we must resist the temptation to mistake the tool, a cognitive limb, for the purpose.</p><p class="whitespace-normal break-words">The key lies in preserving what cognitive scientists call <em>desirable difficulties: </em>the <em>productive</em> <em>friction</em> that actually enables learning. Possibly through <a href="https://fortune.com/2025/09/07/stanford-professor-jure-leskovec-hand-written-graded-tests-ai/" target="_blank" rel="noopener noreferrer">written exams</a>, to take a recent case in point from Jure Leskovec, Professor for Computer Science at Stanford University, one of the epicenters of LLM research. When LLMs remove all resistance from the educational process, they may inadvertently remove the very mechanisms through which understanding develops. It's the cognitive equivalent of using a GPS for every journey: efficient, certainly, but we never develop our own sense of direction. The job market might pay a premium for that very skill of being able to read a map.</p><p class="whitespace-normal break-words">Now, how might we design friction back into AI-assisted learning? Most recently, syllabi suggest students could use LLMs to explore multiple perspectives on a topic but be required to defend their own synthesis without algorithmic help. They might employ AI to generate counterarguments to their thesis, forcing them to strengthen their reasoning. </p><p>However, the most promising educational applications of AI might be those that increase rather than decrease meaningful cognitive friction, by design. Imagine an LLM that refuses to answer directly but instead guides students through productive confusion, or one that generates problems tailored to sit just beyond a student's current ability, in what <a href="https://en.wikipedia.org/wiki/Zone_of_proximal_development" target="_blank" rel="noopener noreferrer">Vygotsky</a> called the zone of <em>proximal development</em>. Or they could use LLMs as sophisticated tutors that ask Socratic questions, rather than answers, maintaining the struggle that builds intellectual muscle.</p><figure class="post__image"><img loading="lazy" src="https://jermainkaminski.com/media/posts/19/image.png" alt="" width="2001" height="1334" sizes="(max-width: 1200px) 100vw, 1200px" srcset="https://jermainkaminski.com/media/posts/19/responsive/image-xs.webp 300w, https://jermainkaminski.com/media/posts/19/responsive/image-sm.webp 480w, https://jermainkaminski.com/media/posts/19/responsive/image-md.webp 768w, https://jermainkaminski.com/media/posts/19/responsive/image-xl.webp 1200w, https://jermainkaminski.com/media/posts/19/responsive/image-xxl.webp 1600w, https://jermainkaminski.com/media/posts/19/responsive/image-xxxl.webp 2560w"></figure><h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">The Experience Game</h2><p>A recent <a href="https://time.com/7295195/ai-chatgpt-google-learning-school/" target="_blank" rel="noopener noreferrer">MIT study</a> that went viral claimed to show measurable IQ drops in 18-39 year old who regularly used GPT for problem-solving tasks, sparking a debate about AI's cognitive impacts. While the study's methodology and sample size invite legitimate skepticism, its central concern reflects well-established neuroscience. Research on neuroplasticity demonstrates that effortful learning, or what <a href="https://static1.squarespace.com/static/631f3333434573769b6da366/t/64513774777e291579ff8078/1683044212516/2019.01.09+Bjork.pdf" target="_blank" rel="noopener noreferrer">Bjork &amp; Bjork (2011)</a> term <em>desirable difficulties, </em>creates more robust neural pathways than passive reception of information. When we struggle with a problem, our brains form denser synaptic connections through a process neuroscientists call <a href="https://en.wikipedia.org/wiki/Long-term_potentiation" target="_blank" rel="noopener noreferrer">long-term potentiation</a>. Problem-solving engages deeper memory consolidation in the hippocampus and prefrontal cortex. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010945213001391" target="_blank" rel="noopener noreferrer">fMRI studies</a> show markedly different brain activation patterns when individuals visually engage, for instance via <a href="https://cpb-us-w2.wpmucdn.com/sites.udel.edu/dist/6/132/files/2010/11/Psychological-Science-2014-Mueller-0956797614524581-1u0h0yu.pdf" target="_blank" rel="noopener noreferrer">handwriting</a>.</p><p class="whitespace-normal break-words">As we integrate artificial intelligence into our educational systems, we might recall that moment on the bench when Sean tells Will about his late wife: "<em>Those are the things I miss the most. The little idiosyncrasies that only I know about. That's what made her my wife.</em>" His point isn't about love, it's about the irreplaceable nature of lived experience. Those idiosyncrasies couldn't be summarized or transferred; they had to be discovered through years of attention, presence, and possibly <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/joms.12890" target="_blank" rel="noopener noreferrer">serendipity</a>.</p><p>Ironically, while modern LLMs might pass Turing's <a href="https://academic.oup.com/mind/article-abstract/LIX/236/433/986238" target="_blank" rel="noopener noreferrer"><em>Imitation Game</em></a> through text, they fail what we might call the 'Sistine Chapel Test', not whether they can describe experience convincingly, but whether they've had experience at all. Turing proposed to consider the question, "<em>Can machines think?</em>." Sean asks us whether knowledge without experience is knowledge at all.</p></div><footer class="content__footer"><div class="content__inner content__footer-inner"><div class="content__updated">Updated: <time datetime="2025-09-10T16:33">September 10, 2025</time></div><div class="content__actions"></div></div></footer></article></div></div></main><footer class="footer s-t-2 s-b-2"><div class="wrapper footer__inner"><a class="footer__logo" href="https://jermainkaminski.com/">Jermain C. Kaminski</a><div class="footer__social"></div><ul class="footer__nav"><li><a href="https://jermainkaminski.com/welcome/" target="_self">About</a></li><li><a href="https://jermainkaminski.com/research/" target="_self">Research</a></li><li><a href="https://jermainkaminski.com/publications/" target="_self">Publications</a></li><li><a href="https://jermainkaminski.com/speaking-and-workshops/" target="_self">Speaking</a></li><li><a href="https://jermainkaminski.com/students/" target="_self">Students</a></li><li><a href="https://jermainkaminski.com/teaching/" target="_self">Teaching</a></li><li><a href="mailto:j.kaminski@maastrichtuniversity.nl" target="_self">Contact</a></li><li><a href="https://bsky.app/profile/jermainkaminski.bsky.social">Bluesky</a></li></ul><div class="footer__copy">Powered by GitHub.</div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://jermainkaminski.com/assets/svg/svg-map.svg#toparrow"/></svg></button></footer><script defer="defer" src="https://jermainkaminski.com/assets/js/scripts.min.js?v=a2f166b35e58753d38a89c4cb3fb61bd"></script><script>window.publiiThemeMenuConfig = {    
      mobileMenuMode: 'sidebar',
      animationSpeed: 300,
      submenuWidth: 'auto',
      doubleClickTime: 500,
      mobileMenuExpandableSubmenus: false, 
      relatedContainerForOverlayMenuSelector: '.navbar',
   };</script><script>var images = document.querySelectorAll('img[loading]');

      for (var i = 0; i < images.length; i++) {
         if (images[i].complete) {
               images[i].classList.add('is-loaded');
         } else {
               images[i].addEventListener('load', function () {
                  this.classList.add('is-loaded');
               }, false);
         }
      }</script><script>window.publiiStaticSearchConfig = { 
					baseURL: 'https://jermainkaminski.com',
					minCharCount: 3,
					maxResultsCount: 10,
					showPopupOnInputClick: true,
					customTriggerSelector: '',
					engineSettings: {
						tokenize: 'forward',
						charset: 'latin:extra',
						language: 'en-GB',
						cache: false,
						suggest: true
					},
					indexSettings: {
						resultsDescription: 'off',
						indexPostTitles: true,
						indexPostExcerpts: true,
						indexPostHeadings: true,
						indexPostAuthors: true,
						indexPostMetaDescription: true,
						indexPageTitles: true,
						indexPageExcerpts: true,
						indexPageHeadings: true,
						indexPageMetaDescription: true,
						indexTagNames: true,
						indexTagDescription: true,
						indexTagMetaDescription: true,
						indexPostConfig: false,
						indexPageConfig: false
					},
					translations: {
						inputPlaceholder: 'Search...',
						searchEmptyState: 'Type to start a search',
						tooShortPhraseState: 'Enter at least 3 characters to search...',
						noResults: 'No results found!',
						buttonClose: 'Close'
					}
				};</script><script src="https://jermainkaminski.com/media/plugins/staticSearch/flexsearch.bundle.js"></script><script src="https://jermainkaminski.com/media/plugins/staticSearch/static.search.min.js"></script></body></html>